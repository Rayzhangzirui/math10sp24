{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7 (Due 5/31)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name:\n",
    "\n",
    "### ID:\n",
    "\n",
    "### Instructions\n",
    "Run everything (select cell in the menu, and click Run all), export as pdf, and submit the pdf to gradescope. \n",
    "\n",
    "To export as pdf, you can use the following methods: (1) File -> download as -> pdf (2) print as pdf from browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**\n",
    "\n",
    "In Q1 and Q2, we show that the multiclass logistic regression is a generalization of the binary logistic regression. The notations follow the [notes on multiclass logistic regression](../notes/logistic_multiclass.ipynb) and the [notes on binary logistic regression](../notes/logistic_binary.ipynb).\n",
    "\n",
    "Suppose $x\\in \\mathbb{R}^p$ and we **do not have the intercept term**.\n",
    "\n",
    "For binary logistic regression, we assume the probability of $x$ belonging to class 1 is \n",
    "\n",
    "$$p(x) = \\frac{1}{1+e^{-\\beta^T x}}$$\n",
    "\n",
    "and the probability of $x$ belonging to class 2 is\n",
    "\n",
    "$$1-p(x) = \\frac{e^{-\\beta^T x}}{1+e^{-\\beta^T x}}$$\n",
    "\n",
    "where $\\beta \\in \\mathbb{R}^p$ is vector of coefficients.\n",
    "\n",
    "\n",
    "For multiclass logistic regression, suppose $K=2$, the predicted probability of class 1 and class 2 are given by\n",
    "\n",
    "$$f_1(x) = \\frac{e^{{w_1}^T x}}{e^{{w_1}^T x} + e^{{w_2}^T x}}$$\n",
    "\n",
    "$$f_2(x) = \\frac{e^{{w_2}^T x}}{e^{{w_1}^T x} + e^{{w_2}^T x}}$$\n",
    "\n",
    "where $w_1, w_2 \\in \\mathbb{R}^p$ are the vectors of coefficients.\n",
    "\n",
    "\n",
    "Show that when $\\beta = w_1 - w_2$, the predicted probability of class 1 and class 2 in the multiclass logistic regression is the same as the binary logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b960c69d",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**\n",
    "\n",
    "Let $y_{ij}$ be the indicator function for class $k$ for the $i$-th sample for $i$=1,...,n and $j$=1,...,K. That is, $y_{ij}=1$ if the $i$-th sample belongs to class $j$ and $y_{ij}=0$ otherwise.\n",
    "\n",
    "For multiclass logistic regression, the cross entropy loss is given by\n",
    "\n",
    "$$L = -\\sum_{i=1}^n \\sum_{j=1}^K y_{ij} \\log f_j(x_i)$$\n",
    "\n",
    "When $K=2$, use results from **Q1**, show that this is the same as the binary cross-entropy loss\n",
    "\n",
    "Hint: use the fact that $y_{i1} + y_{i2} = 1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bdcfb4",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following problems, we will use the penguins dataset.\n",
    "\n",
    "We will use ``[bill_length_mm, bill_depth_mm]`` as the features to predict the species of penguins.\n",
    "\n",
    "We will explore different classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT modify this cell\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = sns.load_dataset('penguins')\n",
    "\n",
    "# Drop rows with missing values\n",
    "features = ['bill_length_mm', 'bill_depth_mm']\n",
    "label = 'species'\n",
    "df.dropna(subset=features + [label], inplace=True)\n",
    "\n",
    "# scale the features\n",
    "scaler = StandardScaler()\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "\n",
    "X = df[features]\n",
    "y = df[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3**\n",
    "\n",
    "Use the multiclass logistic regression model\n",
    "\n",
    "(1) Fit a logistic regression model to predict the species.\n",
    "\n",
    "(2) Report the accuracy of the model.\n",
    "\n",
    "(3) Visualize the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c83ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**\n",
    "\n",
    "Use the kNN classifier to predict the species. First, we need to find the best k.\n",
    "\n",
    "Use 5-fold cross validation, find the k that gives the best average accuracy. Try k=1,2,...,9. Set `random_state=0` for the KFold object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3475b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**\n",
    "\n",
    "Use the optimal $k$ obtained from **Q4**, perform the following tasks:\n",
    "    \n",
    "(1) Fit a kNN classifier to predict the species.\n",
    "\n",
    "(2) Report the accuracy of the model.\n",
    "\n",
    "(3) Visualize the decision boundary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c556bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
